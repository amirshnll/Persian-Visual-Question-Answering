{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1bdebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms as T\n",
    "from torch.backends import cudnn\n",
    "\n",
    "from src.val import val\n",
    "from src.train import train\n",
    "from src.models.resnexts import Model\n",
    "from src.tools.pyutils import set_seed, save_file, load_file\n",
    "from configurations.configs import get_configs\n",
    "from src.datasets.VQAv1 import get_data_loader\n",
    "from src.datasets.preparing import get_original_data\n",
    "from src.preprocessing.data import (\n",
    "    translate_data,\n",
    "    remove_repeated_data,\n",
    "    remove_english_qas\n",
    ")\n",
    "from src.preprocessing.questions import (\n",
    "    tokenize_questions,\n",
    "    get_tokens_length_frequency,\n",
    "    filter_by_tokens_length,\n",
    "    get_tokens_frequency,\n",
    "    get_useful_tokens,\n",
    "    get_tokens_dictionary\n",
    ")\n",
    "from src.preprocessing.annotations import (\n",
    "    get_answers_frequency,\n",
    "    get_k_frequent_answers,\n",
    "    filter_by_k_frequent_answers,\n",
    "    get_answers_dictionary\n",
    ")\n",
    "from src.tools.imgutils import extract_features\n",
    "from src.tools.torchutils import get_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf84ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable CuDNN\n",
    "cudnn.enabled = True\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69abe012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Configurations\n",
    "cfgs = get_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831cb50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random State\n",
    "set_seed(seed=cfgs['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282aa443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Original Data\n",
    "original_data = get_original_data(cfgs=cfgs)\n",
    "print('Getting Original Data:')\n",
    "print(f'Train Data: {len(original_data[\"VQAv1\"][\"train\"])}')\n",
    "print(f'Val Data: {len(original_data[\"VQAv1\"][\"val\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train and Val Data\n",
    "train_data = original_data[\"VQAv1\"][\"train\"]\n",
    "val_data = original_data[\"VQAv1\"][\"val\"]\n",
    "print('Analyzing Data ...')\n",
    "print(f'Train Data: {len(train_data)}')\n",
    "print(f'# Unique question_id: {len(set([d[\"question_id\"] for d in train_data]))}')\n",
    "print(f'# Unique image_id: {len(set([d[\"image_id\"] for d in train_data]))}')\n",
    "print(f'# Unique en_answer: {len(set([d[\"en_answer\"] for d in train_data]))}')\n",
    "print(f'# Unique en_question: {len(set([d[\"en_question\"] for d in train_data]))}')\n",
    "print(f'# Unique (A, Q): {len(set([(d[\"en_answer\"], d[\"en_question\"]) for d in train_data]))}')\n",
    "print(f'# Unique (A, Q, I): {len(set([(d[\"en_answer\"], d[\"en_question\"], d[\"image_id\"]) for d in train_data]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Data:\n",
    "train_data = translate_data(\n",
    "    data=train_data,\n",
    "    save_path=cfgs['preprocess']['root_path'],\n",
    "    dictionary_name=cfgs['preprocess']['dictionary_name']\n",
    ")\n",
    "print(f'Train Data: {len(train_data)}')\n",
    "print(f'# Unique question_id: {len(set([d[\"question_id\"] for d in train_data]))}')\n",
    "print(f'# Unique image_id: {len(set([d[\"image_id\"] for d in train_data]))}')\n",
    "print(f'# Unique fa_answer: {len(set([d[\"fa_answer\"] for d in train_data]))}')\n",
    "print(f'# Unique fa_question: {len(set([d[\"fa_question\"] for d in train_data]))}')\n",
    "print(f'# Unique (A, Q): {len(set([(d[\"fa_answer\"], d[\"fa_question\"]) for d in train_data]))}')\n",
    "print(f'# Unique (A, Q, I): {len(set([(d[\"fa_answer\"], d[\"fa_question\"], d[\"image_id\"]) for d in train_data]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4932f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removing repeated data:\n",
    "train_data = remove_repeated_data(data=train_data)\n",
    "print('After removing repeated data ...')\n",
    "print(f'Train Data: {len(train_data)}')\n",
    "print(f'# Unique question_id: {len(set([d[\"question_id\"] for d in train_data]))}')\n",
    "print(f'# Unique image_id: {len(set([d[\"image_id\"] for d in train_data]))}')\n",
    "print(f'# Unique fa_answer: {len(set([d[\"fa_answer\"] for d in train_data]))}')\n",
    "print(f'# Unique fa_question: {len(set([d[\"fa_question\"] for d in train_data]))}')\n",
    "print(f'# Unique (A, Q): {len(set([(d[\"fa_answer\"], d[\"fa_question\"]) for d in train_data]))}')\n",
    "print(f'# Unique (A, Q, I): {len(set([(d[\"fa_answer\"], d[\"fa_question\"], d[\"image_id\"]) for d in train_data]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89ccbe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove English questions and answers if exists\n",
    "train_data = remove_english_qas(data=train_data)\n",
    "print(f'After removing english questions and answers: {len(train_data)}')\n",
    "print(f'Train Data: {len(train_data)}')\n",
    "print(f'# Unique question_id: {len(set([d[\"question_id\"] for d in train_data]))}')\n",
    "print(f'# Unique image_id: {len(set([d[\"image_id\"] for d in train_data]))}')\n",
    "print(f'# Unique fa_answer: {len(set([d[\"fa_answer\"] for d in train_data]))}')\n",
    "print(f'# Unique fa_question: {len(set([d[\"fa_question\"] for d in train_data]))}')\n",
    "print(f'# Unique (A, Q): {len(set([(d[\"fa_answer\"], d[\"fa_question\"]) for d in train_data]))}')\n",
    "print(f'# Unique (A, Q, I): {len(set([(d[\"fa_answer\"], d[\"fa_question\"], d[\"image_id\"]) for d in train_data]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "## Translating\n",
    "print(f'Val Data: {len(val_data)}')\n",
    "print(f'# Unique (A, Q, I): {len(set([(d[\"en_answer\"], d[\"en_question\"], d[\"image_id\"]) for d in val_data]))}')\n",
    "\n",
    "val_data = translate_data(\n",
    "    data=val_data,\n",
    "    save_path=cfgs['preprocess']['root_path'],\n",
    "    dictionary_name=cfgs['preprocess']['dictionary_name']\n",
    ")\n",
    "print(f'Val Data: {len(val_data)}')\n",
    "print(f'# Unique (A, Q, I): {len(set([(d[\"fa_answer\"], d[\"fa_question\"], d[\"image_id\"]) for d in val_data]))}')\n",
    "\n",
    "val_data = remove_repeated_data(data=val_data)\n",
    "print(f'Val Data: {len(val_data)}')\n",
    "print(f'# Unique (A, Q, I): {len(set([(d[\"fa_answer\"], d[\"fa_question\"], d[\"image_id\"]) for d in val_data]))}')\n",
    "\n",
    "val_data = remove_english_qas(data=val_data)\n",
    "print(f'Val Data: {len(val_data)}')\n",
    "print(f'# Unique (A, Q, I): {len(set([(d[\"fa_answer\"], d[\"fa_question\"], d[\"image_id\"]) for d in val_data]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fad778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data by k frequent answers\n",
    "dataset = train_data + val_data\n",
    "print(f'Dataset: {len(dataset)}')\n",
    "\n",
    "answers_frequency = get_answers_frequency(data=dataset)\n",
    "print(f'Number of unique answers: {len(answers_frequency)}')\n",
    "\n",
    "k_frequent_answers = get_k_frequent_answers(answers_frequency=answers_frequency, k=1000)\n",
    "\n",
    "print(f'{len(k_frequent_answers)}/{len(answers_frequency)} = {len(k_frequent_answers) / len(answers_frequency)}')\n",
    "print(f'{sum([v for k, v in k_frequent_answers.items()])}/{len(dataset)} = '\n",
    "      f'{(sum([v for k, v in k_frequent_answers.items()]))/len(dataset)}')\n",
    "print(f'Max: {max(k_frequent_answers.items(), key=lambda x: x[1])}')\n",
    "print(f'Min: {min(k_frequent_answers.items(), key=lambda x: x[1])}')\n",
    "\n",
    "train_data = filter_by_k_frequent_answers(data=train_data, answers=k_frequent_answers)\n",
    "print('After filtering by k frequent answers ...')\n",
    "print(f'Train Data: {len(train_data)}')\n",
    "print(f'# Unique question_id: {len(set([d[\"question_id\"] for d in train_data]))}')\n",
    "print(f'# Unique image_id: {len(set([d[\"image_id\"] for d in train_data]))}')\n",
    "print(f'# Unique fa_answer: {len(set([d[\"fa_answer\"] for d in train_data]))}')\n",
    "print(f'# Unique fa_question: {len(set([d[\"fa_question\"] for d in train_data]))}')\n",
    "print(f'# Unique (A, Q): {len(set([(d[\"fa_answer\"], d[\"fa_question\"]) for d in train_data]))}')\n",
    "print(f'# Unique (A, Q, I): {len(set([(d[\"fa_answer\"], d[\"fa_question\"], d[\"image_id\"]) for d in train_data]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541679b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Train Data\n",
    "## Step 1: Preprocessing Questions\n",
    "### Tokenize Questions\n",
    "train_data = tokenize_questions(data=train_data)\n",
    "tokens_length_frequency = get_tokens_length_frequency(data=train_data)\n",
    "print(f'Tokens Length Freqs: {tokens_length_frequency}')\n",
    "print(f'Train Data: {len(train_data)}')\n",
    "print(f'# Unique question_id: {len(set([d[\"question_id\"] for d in train_data]))}')\n",
    "print(f'# Unique image_id: {len(set([d[\"image_id\"] for d in train_data]))}')\n",
    "print(f'# Unique fa_answer: {len(set([d[\"fa_answer\"] for d in train_data]))}')\n",
    "print(f'# Unique fa_question: {len(set([d[\"fa_question\"] for d in train_data]))}')\n",
    "print(f'# Unique tokens: {len(set([t for d in train_data for t in d[\"tokens\"]]))}')\n",
    "print(f'# Unique (A, T): {len(set([(d[\"fa_answer\"], tuple(d[\"tokens\"])) for d in train_data]))}')\n",
    "print(f'# Unique (A, T, I): {len(set([(d[\"fa_answer\"], tuple(d[\"tokens\"]), d[\"image_id\"]) for d in train_data]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26365ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Limit Questions by length\n",
    "tokens_length = 20\n",
    "train_data = filter_by_tokens_length(data=train_data, tokens_length=tokens_length)\n",
    "print(f'Train Data: {len(train_data)}')\n",
    "print(f'# Unique question_id: {len(set([d[\"question_id\"] for d in train_data]))}')\n",
    "print(f'# Unique image_id: {len(set([d[\"image_id\"] for d in train_data]))}')\n",
    "print(f'# Unique fa_answer: {len(set([d[\"fa_answer\"] for d in train_data]))}')\n",
    "print(f'# Unique fa_question: {len(set([d[\"fa_question\"] for d in train_data]))}')\n",
    "print(f'# Unique tokens: {len(set([t for d in train_data for t in d[\"tokens\"]]))}')\n",
    "print(f'# Unique (A, T): {len(set([(d[\"fa_answer\"], tuple(d[\"tokens\"])) for d in train_data]))}')\n",
    "print(f'# Unique (A, T, I): {len(set([(d[\"fa_answer\"], tuple(d[\"tokens\"]), d[\"image_id\"]) for d in train_data]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter Questions by k frequents words (tokens)\n",
    "tokens_frequency = get_tokens_frequency(data=train_data)\n",
    "print(f'Number of unique tokens: {len(tokens_frequency)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db132251",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_occ = 5\n",
    "useful_tokens = get_useful_tokens(tokens_frequency=tokens_frequency, min_occ=min_occ)\n",
    "print(f'{len(useful_tokens)}/{len(tokens_frequency)} = {len(useful_tokens) / len(tokens_frequency)}')\n",
    "print(f'{sum([v for k, v in useful_tokens.items()])}/{sum([v for k, v in tokens_frequency.items()])} = '\n",
    "      f'{(sum([v for k, v in useful_tokens.items()]))/(sum([v for k, v in tokens_frequency.items()]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937699b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Preparation\n",
    "idx_to_token, token_to_idx = get_tokens_dictionary(\n",
    "    useful_tokens=useful_tokens,\n",
    "    save_path=cfgs['preprocess']['root_path'],\n",
    "    idx_to_token_save_name=cfgs['preprocess']['idx_to_token'],\n",
    "    token_to_idx_save_name=cfgs['preprocess']['token_to_idx'],\n",
    ")\n",
    "idx_to_answer, answer_to_idx = get_answers_dictionary(\n",
    "    answers=k_frequent_answers,\n",
    "    save_path=cfgs['preprocess']['root_path'],\n",
    "    idx_to_answer_save_name=cfgs['preprocess']['idx_to_answer'],\n",
    "    answer_to_idx_save_name=cfgs['preprocess']['answer_to_idx'],\n",
    ")\n",
    "\n",
    "print(f'Token Dictionary: {len(token_to_idx)}')\n",
    "print(f'Answer Dictionary: {len(answer_to_idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec1729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Validation Data:\n",
    "val_data = filter_by_k_frequent_answers(data=val_data, answers=k_frequent_answers)\n",
    "val_data = tokenize_questions(data=val_data)\n",
    "val_data = filter_by_tokens_length(data=val_data, tokens_length=tokens_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce904511",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'# Unique fa_answer: {len(set([d[\"fa_answer\"] for d in val_data]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Features:\n",
    "train_trans = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Resize(size=(224, 224)),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "val_trans = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Resize(size=(224, 224)),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "train_data = extract_features(\n",
    "    data=train_data,\n",
    "    trans=train_trans,\n",
    "    device=device,\n",
    "    save_path=cfgs['preprocess']['image_features']\n",
    ")\n",
    "\n",
    "val_data = extract_features(\n",
    "    data=val_data,\n",
    "    trans=val_trans,\n",
    "    device=device,\n",
    "    save_path=cfgs['preprocess']['image_features']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a1a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Datasets and Dataloaders:\n",
    "trainloader = get_data_loader(\n",
    "    data=train_data,\n",
    "    token_to_idx=token_to_idx,\n",
    "    answer_to_idx=answer_to_idx,\n",
    "    tokens_length=tokens_length,\n",
    "    trans=train_trans,\n",
    "    batch_size=cfgs['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "valloader = get_data_loader(\n",
    "    data=val_data,\n",
    "    token_to_idx=token_to_idx,\n",
    "    answer_to_idx=answer_to_idx,\n",
    "    tokens_length=tokens_length,\n",
    "    trans=val_trans,\n",
    "    batch_size=cfgs['batch_size'],\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db564f9",
   "metadata": {},
   "source": [
    "# Preparing Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f39f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = Model(\n",
    "    vocabulary_size=len(token_to_idx) + 1,  # +1 for padding\n",
    "    num_classes=len(answer_to_idx),\n",
    "    tokens_length=tokens_length,\n",
    "    hidden_size=512,\n",
    "    embed_dim=512,\n",
    "    dropout=0.30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d47423",
   "metadata": {},
   "source": [
    "# Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea2887",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_loss = np.inf\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=cfgs['lr'])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = model.to(device=device)\n",
    "train_batch_global_step = 1\n",
    "val_batch_global_step = 1\n",
    "history = {\n",
    "    'train_accuracy': [],\n",
    "    'train_loss': [],\n",
    "    'val_accuracy': [],\n",
    "    'val_loss': []\n",
    "}\n",
    "\n",
    "for i in range(cfgs['epochs']):\n",
    "    print(f'Epoch: {i+1}')\n",
    "    \n",
    "    model, train_scores, train_batch_global_step = train(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        dataloader=trainloader,\n",
    "        device=device,\n",
    "        global_step=train_batch_global_step\n",
    "    )\n",
    "    history['train_accuracy'].append(train_scores['accuracy'])\n",
    "    history['train_loss'].append(train_scores['loss'])\n",
    "    \n",
    "    \n",
    "    val_scores, val_batch_global_step = val(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        dataloader=valloader,\n",
    "        device=device,\n",
    "        global_step=val_batch_global_step\n",
    "    )\n",
    "    history['val_accuracy'].append(val_scores['accuracy'])\n",
    "    history['val_loss'].append(val_scores['loss'])\n",
    "    \n",
    "    if train_scores['loss'] < best_loss:\n",
    "        best_loss = train_scores['loss']\n",
    "        save_file(data=history, path=cfgs['root_path'], file_name=f'History_{i+1}.pickle')\n",
    "        torch.save(obj=model.state_dict(), f=os.path.join(cfgs['root_path'], f'Model_{i+1}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = load_file(path=os.path.join(cfgs['root_path'], 'History_E20.pickle'))\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "axes[0].plot(history['train_accuracy'], label='Train Accuracy')\n",
    "axes[0].plot(history['val_accuracy'], label='Val Accuracy')\n",
    "axes[0].set_title('Accuracy')\n",
    "axes[0].grid()\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history['train_loss'], label='Train Loss')\n",
    "axes[1].plot(history['val_loss'], label='Val Loss')\n",
    "axes[1].set_title('Loss')\n",
    "axes[1].grid()\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40afba97",
   "metadata": {},
   "source": [
    "# Try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdfebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from src.preprocessing.questions import tokenize_questions, filter_by_tokens_length\n",
    "from src.tools.pyutils import load_file\n",
    "from torchvision import transforms as T\n",
    "from src.models.resnexts import Model, FeatureExtractor\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81699d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, question, model, token_to_idx, answer_to_idx, idx_to_answer, tokens_length, max_ans=5):\n",
    "    FE = FeatureExtractor()\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    trans = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Resize(size=(224, 224)),\n",
    "#         T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "    img = trans(img).unsqueeze(0)\n",
    "    img_fea = FE(img)\n",
    "    \n",
    "    q = [{'fa_question': question}]\n",
    "    q = tokenize_questions(q)\n",
    "    q = filter_by_tokens_length(q, tokens_length)\n",
    "    q = q[0]['tokens']\n",
    "\n",
    "    question = torch.zeros(size=(tokens_length, ), dtype=torch.long)\n",
    "    for i in range(len(q)):\n",
    "        if i < tokens_length:\n",
    "            question[i] = token_to_idx.get(q[i], token_to_idx['UKN'])\n",
    "    question = question.unsqueeze(0)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(img_fea, question)[0]\n",
    "    pred = torch.softmax(pred, dim=0)\n",
    "    \n",
    "    answers = torch.topk(input=pred, dim=0, k=max_ans)\n",
    "\n",
    "    for i in range(max_ans):\n",
    "        print(f'Answer {i+1}: {idx_to_answer[answers[1][i].item()]}, Probability: {answers[0][i].item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e579a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'Model_20.pth'\n",
    "token_to_idx = load_file(path=os.path.join(cfgs['preprocess']['root_path'], cfgs['preprocess']['token_to_idx'])\n",
    "answer_to_idx = load_file(path=os.path.join(cfgs['preprocess']['root_path'], cfgs['preprocess']['answer_to_idx'])\n",
    "idx_to_answer = load_file(path=os.path.join(cfgs['preprocess']['root_path'], cfgs['preprocess']['idx_to_answer'])\n",
    "tokens_length = 20\n",
    "\n",
    "model = Model(\n",
    "    vocabulary_size=len(token_to_idx) + 1,  # +1 for padding\n",
    "    num_classes=len(answer_to_idx),\n",
    "    tokens_length=tokens_length,\n",
    "    hidden_size=512,\n",
    "    embed_dim=512,\n",
    "    dropout=0,\n",
    ")\n",
    "\n",
    "weights = torch.load(weights_path)\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e9fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It Should be in test_images path in root\n",
    "image_path = 'test_images/2.jpeg'\n",
    "question = 'در این تصویر چند پسر عینک دارند'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1605e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(image_path, question, model, token_to_idx, answer_to_idx, idx_to_answer, tokens_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
